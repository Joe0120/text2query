# text2query

ä¸€å€‹ç”¨æ–¼å°‡è‡ªç„¶èªè¨€è½‰æ›ç‚ºè³‡æ–™åº«æŸ¥è©¢çš„ Python å¥—ä»¶ï¼Œæ”¯æ´å¤šç¨®è³‡æ–™åº«é¡å‹ä¸¦æ•´åˆ LlamaIndex LLMã€‚

## åŠŸèƒ½ç‰¹è‰²

- ğŸ¤– **Text-to-SQL/NoSQL**ï¼šå°‡è‡ªç„¶èªè¨€å•é¡Œè½‰æ›ç‚ºè³‡æ–™åº«æŸ¥è©¢
- ğŸ”„ **ç•°æ­¥åŸ·è¡Œ**ï¼šå®Œæ•´çš„ç•°æ­¥è³‡æ–™åº«æŸ¥è©¢æ”¯æ´
- ğŸ—„ï¸ **å¤šè³‡æ–™åº«æ”¯æ´**ï¼šPostgreSQL, MySQL, SQLite, MongoDB
- ğŸ”Œ **LLM æ•´åˆ**ï¼šä½¿ç”¨æ‚¨è‡ªå·±çš„ LlamaIndex LLM å¯¦ä¾‹
- ğŸ›¡ï¸ **å®‰å…¨æª¢æŸ¥**ï¼šå…§å»ºæŸ¥è©¢å®‰å…¨é©—è­‰æ©Ÿåˆ¶
- ğŸ“Š **çµæ§‹åˆ†æ**ï¼šè‡ªå‹•åˆ†æè³‡æ–™åº«çµæ§‹ä¾› LLM åƒè€ƒ
- ğŸ§  **RAG è¨“ç·´è³‡æ–™ç®¡ç†**ï¼šTrainingStore æ¨¡çµ„æ”¯æ´å‘é‡ç›¸ä¼¼åº¦æœå°‹å’Œæ¬Šé™æ§åˆ¶

## ä½¿ç”¨æ–¹å¼ï¼ˆä½œç‚º Git Submoduleï¼‰

### 1. æ·»åŠ  Submodule

åœ¨ä½ çš„å°ˆæ¡ˆä¸­æ·»åŠ  text2query ä½œç‚º submoduleï¼š

```bash
git submodule add https://github.com/Joe0120/text2query.git libs/text2query
git submodule update --init --recursive
```

### 2. å®‰è£ä¾è³´

```bash
pip install -r libs/text2query/requirements.txt
```

å¦‚éœ€ä½¿ç”¨ Text-to-SQL åŠŸèƒ½ï¼Œé‚„éœ€å®‰è£ LlamaIndexï¼š

```bash
pip install llama-index llama-index-llms-openai  # æˆ–å…¶ä»– LLM å¥—ä»¶
```

å¦‚éœ€ä½¿ç”¨ RAG è¨“ç·´è³‡æ–™åŠŸèƒ½ï¼Œé‚„éœ€å®‰è£ pgvectorï¼š

```bash
# PostgreSQL éœ€è¦å®‰è£ pgvector æ“´å±•
# Ubuntu/Debian: apt install postgresql-16-pgvector
# macOS: brew install pgvector
pip install pgvector
```

## ä½¿ç”¨ç¯„ä¾‹

### åŸºæœ¬æŸ¥è©¢åŸ·è¡Œ

#### PostgreSQL ç¯„ä¾‹

```python
from text2query.core.connections import PostgreSQLConfig
from text2query.adapters.sql.postgresql import PostgreSQLAdapter

# å»ºç«‹é€£ç·šé…ç½®
config = PostgreSQLConfig(
    database_name="mydb",
    host="localhost",
    port=5432,
    username="user",
    password="password"
)

# å»ºç«‹ adapter
adapter = PostgreSQLAdapter(config)

# æ¸¬è©¦é€£ç·š
success, message = await adapter.test_connection()
print(f"é€£ç·šç‹€æ…‹: {message}")

# åŸ·è¡ŒæŸ¥è©¢
result = await adapter.sql_execution("SELECT * FROM users LIMIT 10")
print(result)
```

#### MongoDB ç¯„ä¾‹

```python
from text2query.core.connections import MongoDBConfig
from text2query.adapters.nosql.mongodb import MongoDBAdapter

# å»ºç«‹é€£ç·šé…ç½®
config = MongoDBConfig(
    host="localhost",
    port=27017,
    database_name="mydb",
    username="admin",
    password="password",
    auth_database="admin"
)

# å»ºç«‹ adapter
adapter = MongoDBAdapter(config)

# åŸ·è¡ŒæŸ¥è©¢ï¼ˆæ”¯æ´å­—ä¸²æˆ–å­—å…¸æ ¼å¼ï¼‰
result = await adapter.sql_execution('db.users.find({"age": {"$gt": 18}}).limit(10)')
print(result)
```

### RAG è¨“ç·´è³‡æ–™ç®¡ç†

TrainingStore æä¾›å®Œæ•´çš„ RAG è¨“ç·´è³‡æ–™ç®¡ç†åŠŸèƒ½ï¼Œæ”¯æ´å‘é‡ç›¸ä¼¼åº¦æœå°‹å’Œéˆæ´»çš„æ¬Šé™æ§åˆ¶ï¼š

```python
from text2query.core.connections import PostgreSQLConfig
from text2query.core.training import TrainingStore
from llama_index.embeddings.openai import OpenAIEmbedding  # æˆ–å…¶ä»– embedder
import uuid

# 1. åˆå§‹åŒ– TrainingStore å’Œ Embedderï¼ˆæ‡‰ç”¨å•Ÿå‹•æ™‚åŸ·è¡Œä¸€æ¬¡ï¼‰
# å‰µå»º embedderï¼ˆæ”¯æ´ä»»ä½• LlamaIndex ç›¸å®¹çš„ embedderï¼‰
embedder = OpenAIEmbedding(
    model="text-embedding-3-small",
    dimensions=768,
)

# åˆå§‹åŒ– TrainingStore ä¸¦å‚³å…¥ embedder
store = await TrainingStore.initialize(
    postgres_config=PostgreSQLConfig(
        host="localhost",
        port=5432,
        database_name="your_db",
        username="user",
        password="password",
    ),
    training_schema="wisbi",  # è‡ªè¨‚ schema åç¨±
    embedding_dim=768,        # å‘é‡ç¶­åº¦
    embedder=embedder,        # å‚³å…¥ embedderï¼Œè‡ªå‹•ç”Ÿæˆ embedding
)

# 2. æ–°å¢è¨“ç·´è³‡æ–™

# æ–°å¢å•ç­”å°
qna_id = await store.insert_qna(
    table_id="employees",  # å¿…å¡«ï¼šè³‡æ–™è¡¨ IDï¼ˆå­—ä¸²ï¼‰
    question="å¦‚ä½•æŸ¥è©¢æ‰€æœ‰å“¡å·¥ï¼Ÿ",
    answer_sql="SELECT * FROM employees",
    user_id="alice",    # å¯é¸ï¼šä½¿ç”¨è€… ID
    group_id="sales",   # å¯é¸ï¼šç¾¤çµ„ ID
    metadata={"source": "manual", "type": "basic_query"},
)

# æ–°å¢ SQL ç¯„ä¾‹
sql_id = await store.insert_sql_example(
    table_id="employees",
    content="SELECT COUNT(*) FROM employees WHERE active = true",
    user_id="alice",
    group_id="sales",
    metadata={"type": "count_query"},
)

# æ–°å¢æ–‡ä»¶èªªæ˜
doc_id = await store.insert_documentation(
    table_id="employees",
    title="å“¡å·¥è¡¨èªªæ˜",
    content="employees è¡¨åŒ…å«æ‰€æœ‰å“¡å·¥çš„åŸºæœ¬è³‡è¨Š",
    user_id="alice",
    group_id="sales",
    metadata={"type": "table_doc"},
)

# 3. æœå°‹è¨“ç·´è³‡æ–™ï¼ˆå‘é‡ç›¸ä¼¼åº¦æœå°‹ + æ¬Šé™éæ¿¾ï¼‰
query = "å“¡å·¥è³‡æ–™æŸ¥è©¢"
query_embedding = embedder.get_text_embedding(query)

# æ”¯æ´ä¸‰ç¨® table_path æ ¼å¼ï¼š
# - å–®ä¸€è¡¨ï¼štable_path="mysql.employees"
# - é€šé…ç¬¦ï¼štable_path="mysql.*"ï¼ˆæœå°‹æ‰€æœ‰ mysql è¡¨ï¼‰
# - åˆ—è¡¨ï¼štable_path=["mysql.employees", "mysql.departments"]

# æœå°‹å–®ä¸€è¡¨
search_results = await store.search_all(
    query_embedding=[0.1, 0.2, ...],  # æŸ¥è©¢å‘é‡
    table_id="employees",
    user_id="alice",                  # æœå°‹è€…èº«ä»½
    group_id="sales",
    top_k=5,
)

# æœå°‹æ‰€æœ‰ mysql è¡¨
all_mysql_results = await store.search_all(
    query_embedding=query_embedding,
    table_path="mysql.*",  # é€šé…ç¬¦
    user_id="alice",
    group_id="sales",
    top_k=10,
)

# æœå°‹å¤šå€‹æŒ‡å®šè¡¨
multi_results = await store.search_all(
    query_embedding=query_embedding,
    table_path=["mysql.employees", "mysql.departments"],  # åˆ—è¡¨
    user_id="alice",
    group_id="sales",
    top_k=8,
)

# çµæœæ ¼å¼ï¼š{"qna": [...], "sql_examples": [...], "documentation": [...]}
for table_name, results in search_results.items():
    print(f"{table_name}: {len(results)} ç­†çµæœ")

# 4. æ›´æ–°è¨“ç·´è³‡æ–™ï¼ˆUpsert æ¨¡å¼ï¼‰
"""

# 5. åˆªé™¤è¨“ç·´è³‡æ–™
"""
```

#### å‚³çµ±æ–¹å¼ï¼ˆæ‰‹å‹•æä¾› embeddingï¼‰

å¦‚æœä½ æƒ³æ‰‹å‹•ç®¡ç† embeddingï¼Œä»å¯ä½¿ç”¨å‚³çµ±æ–¹æ³•ï¼š

```python
# ä¸æä¾› embedder çš„åˆå§‹åŒ–
store = await TrainingStore.initialize(
    postgres_config=config,
    training_schema="wisbi",
    embedding_dim=768,
    # ä¸æä¾› embedder
)

# æ‰‹å‹•ç”Ÿæˆ embedding ä¸¦æ’å…¥
embedder = OpenAIEmbedding()
question = "å¦‚ä½•æŸ¥è©¢æ‰€æœ‰å“¡å·¥ï¼Ÿ"
answer_sql = "SELECT * FROM employees"
embedding = embedder.get_text_embedding(f"{question} {answer_sql}")

# ä½¿ç”¨åº•å±¤æ–¹æ³•æ‰‹å‹•å‚³å…¥ embedding
qna_id = await store.insert_qna(
    training_id=training_id,
    table_path="mysql.employees",
    question=question,
    answer_sql=answer_sql,
    embedding=embedding,  # æ‰‹å‹•æä¾› embedding
    user_id="alice",
    group_id="sales",
)
```

#### æ¬Šé™æ§åˆ¶æ¨¡å‹

TrainingStore æ”¯æ´éˆæ´»çš„æ¬Šé™æ§åˆ¶ï¼š

| user_id | group_id | å­˜å–æ¬Šé™ | ä½¿ç”¨æƒ…å¢ƒ |
|---------|----------|----------|----------|
| "alice" | "sales" | åªæœ‰ alice åœ¨ sales ç¾¤çµ„å¯å­˜å– | å€‹äººç§æœ‰è³‡æ–™ï¼ˆé™å®šç¾¤çµ„ï¼‰ |
| "alice" | "" | alice åœ¨ä»»ä½•ç¾¤çµ„éƒ½å¯å­˜å– | å€‹äººè·¨ç¾¤çµ„è³‡æ–™ |
| "" | "sales" | sales ç¾¤çµ„æ‰€æœ‰æˆå“¡å¯å­˜å– | ç¾¤çµ„å…±äº«è³‡æ–™ |
| "" | "" | æ‰€æœ‰äººéƒ½å¯å­˜å– | å…¨å±€å…¬é–‹è³‡æ–™ |

```python
# æ¬Šé™æœå°‹ç¯„ä¾‹
# Alice åœ¨ sales ç¾¤çµ„æœå°‹ â†’ å¯å­˜å–ï¼šå€‹äººç§æœ‰ + å€‹äººè·¨ç¾¤çµ„ + ç¾¤çµ„å…±äº« + å…¨å±€å…¬é–‹
alice_results = await store.search_qna(
    query_embedding=embedding,
    table_id="employees",
    user_id="alice",
    group_id="sales",
    top_k=10,
)

# åŒ¿åä½¿ç”¨è€…æœå°‹ â†’ åªèƒ½å­˜å–ï¼šå…¨å±€å…¬é–‹è³‡æ–™
public_results = await store.search_qna(
    query_embedding=embedding,
    table_id="employees",
    user_id=None,
    group_id=None,
    top_k=10,
)
```

### Text-to-SQL åŠŸèƒ½

ä½¿ç”¨è‡ªç„¶èªè¨€æŸ¥è©¢è³‡æ–™åº«ï¼š

```python
from text2query import Text2SQL
from text2query.adapters.nosql.mongodb import MongoDBAdapter
from text2query.core.connections import MongoDBConfig
from llama_index.llms.openai import OpenAI

# 1. è¨­ç½®è³‡æ–™åº«é€£ç·š
config = MongoDBConfig(
    host="localhost",
    port=27017,
    database_name="employees",
    username="admin",
    password="password"
)
adapter = MongoDBAdapter(config)

# 2. ç²å–è³‡æ–™åº«çµæ§‹
db_structure = await adapter.get_schema_str()

# 3. è¨­ç½® LLMï¼ˆä½¿ç”¨æ‚¨è‡ªå·±çš„ LlamaIndex LLMï¼‰
llm = OpenAI(model="gpt-4", api_key="your-api-key")

# 4. å»ºç«‹ Text2SQL å¯¦ä¾‹
t2s = Text2SQL(
    llm=llm,
    db_structure=db_structure,
    db_type="mongodb"  # æˆ– "postgresql", "mysql", "sqlite"
)

# 5. ä½¿ç”¨è‡ªç„¶èªè¨€ç”ŸæˆæŸ¥è©¢
query = await t2s.generate_query("æ¯å€‹éƒ¨é–€æœ‰å¹¾å€‹ä¸»ç®¡ï¼Ÿåˆ—å‡ºéƒ¨é–€åç¨±å’Œä¸»ç®¡æ•¸é‡")
print(f"ç”Ÿæˆçš„æŸ¥è©¢: {query}")

# 6. åŸ·è¡ŒæŸ¥è©¢
result = await adapter.sql_execution(query)
print(f"æŸ¥è©¢çµæœ: {result}")
```

### ä½¿ç”¨å…¶ä»– LLM

Text2SQL æ”¯æ´ä»»ä½• LlamaIndex ç›¸å®¹çš„ LLMï¼š

```python
# ä½¿ç”¨ LiteLLMï¼ˆæ”¯æ´å¤šç¨® LLM æä¾›å•†ï¼‰
from llama_index.llms.litellm import LiteLLM

llm = LiteLLM(
    model="openai/gpt-4",
    api_base="https://api.openai.com/v1",
    api_key="your-api-key",
    max_tokens=4096,
    temperature=0.1
)

# ä½¿ç”¨ Anthropic Claude
from llama_index.llms.anthropic import Anthropic

llm = Anthropic(
    model="claude-3-opus-20240229",
    api_key="your-api-key"
)

# ç„¶å¾Œç…§å¸¸ä½¿ç”¨ Text2SQL
t2s = Text2SQL(llm=llm, db_structure=db_structure, db_type="postgresql")
```

### é€²éšåŠŸèƒ½

#### è‡ªè¨‚ Prompt æ¨¡æ¿

```python
custom_template = """
çµ¦å®šä»¥ä¸‹è³‡æ–™åº«çµæ§‹ï¼š
{db_structure}

è«‹æ ¹æ“šä»¥ä¸‹å•é¡Œç”Ÿæˆ SQL æŸ¥è©¢ï¼š
{question}

æ³¨æ„äº‹é …ï¼š
- ä½¿ç”¨æ¨™æº– SQL èªæ³•
- ç¢ºä¿æŸ¥è©¢æ•ˆç‡
- æ·»åŠ é©ç•¶çš„ LIMIT é™åˆ¶
"""

t2s.set_custom_template(custom_template)
```

#### ä½¿ç”¨å°è©±æ­·å²

```python
from llama_index.memory import ChatMemoryBuffer

# å»ºç«‹è¨˜æ†¶ç·©è¡
memory = ChatMemoryBuffer.from_defaults(token_limit=3000)

# ä½¿ç”¨è¨˜æ†¶å»ºç«‹ Text2SQL
t2s = Text2SQL(
    llm=llm,
    db_structure=db_structure,
    db_type="postgresql",
    chat_history=memory.memory
)

# é€£çºŒå°è©±
query1 = await t2s.generate_query("é¡¯ç¤ºæ‰€æœ‰ç”¨æˆ¶")
query2 = await t2s.generate_query("åªé¡¯ç¤ºå‰ 10 å€‹")  # æœƒåƒè€ƒä¹‹å‰çš„å°è©±
```

## æ”¯æ´çš„è³‡æ–™åº«

- **SQL**:
  - PostgreSQL - å®Œæ•´æ”¯æ´ï¼ˆå«é€£ç·šæ± ï¼‰
  - MySQL - å®Œæ•´æ”¯æ´
  - SQLite - å®Œæ•´æ”¯æ´
  - SQL Server - å®Œæ•´æ”¯æ´
  - Oracle - å®Œæ•´æ”¯æ´

- **NoSQL**:
  - MongoDB - å®Œæ•´æ”¯æ´ï¼ˆå« aggregate pipelineï¼‰

## API æ–‡ä»¶

### TrainingStore

RAG è¨“ç·´è³‡æ–™ç®¡ç†é¡ï¼Œæ”¯æ´å‘é‡ç›¸ä¼¼åº¦æœå°‹å’Œæ¬Šé™æ§åˆ¶ã€‚

**åˆå§‹åŒ–ï¼š**
```python
store = await TrainingStore.initialize(
    postgres_config=PostgreSQLConfig(...),
    training_schema="wisbi",
    embedding_dim=768,
)
```

**ä¸»è¦æ–¹æ³•ï¼š**

**æ–°å¢è³‡æ–™ï¼š**
- `async insert_qna(table_id, question, answer_sql, embedding, user_id="", group_id="", metadata=None)`: æ–°å¢å•ç­”å°
- `async insert_sql_example(table_id, content, embedding, user_id="", group_id="", metadata=None)`: æ–°å¢ SQL ç¯„ä¾‹
- `async insert_documentation(table_id, content, embedding, title=None, user_id="", group_id="", metadata=None)`: æ–°å¢æ–‡ä»¶èªªæ˜

**æœå°‹è³‡æ–™ï¼š**
- `async search_qna(query_embedding, table_id, user_id=None, group_id=None, top_k=5)`: æœå°‹å•ç­”å°
- `async search_sql_examples(query_embedding, table_id, user_id=None, group_id=None, top_k=5)`: æœå°‹ SQL ç¯„ä¾‹
- `async search_documentation(query_embedding, table_id, user_id=None, group_id=None, top_k=5)`: æœå°‹æ–‡ä»¶èªªæ˜
- `async search_all(query_embedding, table_id, user_id=None, group_id=None, top_k=8)`: æœå°‹æ‰€æœ‰é¡å‹

**æ›´æ–°è³‡æ–™ï¼š**
ï¼ˆå·²ç§»é™¤ training_id ç›¸é—œ upsert ä»‹é¢ï¼‰

**åˆªé™¤è³‡æ–™ï¼š**
ï¼ˆå·²ç§»é™¤ training_id ç›¸é—œåˆªé™¤ä»‹é¢ï¼‰

### Text2SQL

ä¸»è¦çš„ Text-to-SQL è½‰æ›é¡ã€‚

**åƒæ•¸ï¼š**
- `llm` (Any): LlamaIndex LLM å¯¦ä¾‹
- `db_structure` (str): è³‡æ–™åº«çµæ§‹å­—ä¸²ï¼ˆå¾ `adapter.get_schema_str()` ç²å–ï¼‰
- `chat_history` (Optional[Any]): ChatMemoryBuffer.memory æ ¼å¼çš„å°è©±æ­·å²
- `db_type` (str): è³‡æ–™åº«é¡å‹ï¼ˆ"postgresql", "mysql", "mongodb", "sqlite"ï¼‰

**æ–¹æ³•ï¼š**
- `async generate_query(question, include_history=True, stream_thinking=True, show_thinking=True)`: ç”Ÿæˆè³‡æ–™åº«æŸ¥è©¢
- `update_db_structure(db_structure)`: æ›´æ–°è³‡æ–™åº«çµæ§‹
- `set_custom_template(template)`: è¨­ç½®è‡ªè¨‚ prompt æ¨¡æ¿
- `get_config()`: ç²å–ç•¶å‰é…ç½®

### Database Adapters

æ‰€æœ‰ adapter éƒ½ç¹¼æ‰¿è‡ª `BaseQueryComposer` ä¸¦æä¾›ä»¥ä¸‹æ–¹æ³•ï¼š

- `async test_connection()`: æ¸¬è©¦è³‡æ–™åº«é€£ç·š
- `async get_schema_str()`: ç²å–è³‡æ–™åº«çµæ§‹å­—ä¸²
- `async sql_execution(command, params=None, safe=True, limit=1000)`: åŸ·è¡ŒæŸ¥è©¢
- `async close_conn()`: é—œé–‰é€£ç·š

## ä¾è³´é …

æ ¸å¿ƒä¾è³´ï¼ˆåœ¨ `requirements.txt` ä¸­ï¼‰ï¼š
- `asyncpg` - PostgreSQL ç•°æ­¥é©…å‹•
- `aiomysql` - MySQL ç•°æ­¥é©…å‹•
- `motor` - MongoDB ç•°æ­¥é©…å‹•
- `pymongo` - MongoDB é©…å‹•
- `dnspython` - DNS è§£æï¼ˆMongoDBï¼‰
- `opencc-python-reimplemented` - ç¹ç°¡è½‰æ›

Text-to-SQL åŠŸèƒ½éœ€è¦ï¼š
- `llama-index` - LLM æ•´åˆæ¡†æ¶
- ä»»ä½• LlamaIndex ç›¸å®¹çš„ LLM å¥—ä»¶ï¼ˆå¦‚ `llama-index-llms-openai`ï¼‰

RAG è¨“ç·´è³‡æ–™åŠŸèƒ½éœ€è¦ï¼š
- `pgvector` - PostgreSQL å‘é‡æ“´å±•
- PostgreSQL è³‡æ–™åº«ï¼ˆéœ€å®‰è£ pgvector æ“´å±•ï¼‰

## å®‰å…¨æ€§

æœ¬å¥—ä»¶åŒ…å«å¤šå±¤å®‰å…¨æª¢æŸ¥ï¼š

1. **SQL Injection é˜²è­·**ï¼šåƒæ•¸åŒ–æŸ¥è©¢å’Œè¼¸å…¥é©—è­‰
2. **MongoDB æ“ä½œé™åˆ¶**ï¼šç¦æ­¢å±éšªæ“ä½œï¼ˆ`$where`, `$function`, `dropDatabase` ç­‰ï¼‰
3. **æŸ¥è©¢é™åˆ¶**ï¼šè‡ªå‹•æ·»åŠ çµæœæ•¸é‡é™åˆ¶
4. **é€£ç·šé©—è­‰**ï¼šé…ç½®é©—è­‰å’Œé€£ç·šæ¸¬è©¦
5. **æ¬Šé™æ§åˆ¶**ï¼šTrainingStore æä¾›ç´°ç²’åº¦çš„è³‡æ–™å­˜å–æ§åˆ¶

## æˆæ¬Š

æœ¬å°ˆæ¡ˆä¸å«ä»»ä½•é–‹æºæˆæ¬Šï¼Œåƒ…ä¾›ç§äººä½¿ç”¨ã€‚
